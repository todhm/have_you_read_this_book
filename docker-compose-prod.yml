version: '3.6'
services:

  webapp:
    image: todhm/flask_spark_webapp
    working_dir: /app
    command: gunicorn -b 0.0.0.0:8000 --reload -w 4  wsgi:app
    networks:
        - sparknetwork
    deploy:
      placement:
        constraints: [node.hostname == default]
    ports:
      - "8000:8000"
    depends_on:
      - spark-master
      - redis
      - mongo
    environment:
     - SPARK_APPLICATION_PYTHON_LOCATION =/app/wsgi.py
     - SPARK_MASTER_NAME=spark-master
     - SPARK_MASTER_PORT=7077
     - PYSPARK_PYTHON=python3
     - APP_SETTINGS=settings.ProductionConfig

  celery_worker:
    image: todhm/flask_spark_webapp
    working_dir: /app
    command: celery -A celery_worker:celery worker  --loglevel=INFO
    networks:
        - sparknetwork
    ports:
      - "9000:9000"

    deploy:
      placement:
        constraints: [node.hostname == default]

    depends_on:
      - webapp
      - spark-master
      - redis
    environment:
     - "SPARK_MASTER=spark://spark-master:7077"
     - SPARK_APPLICATION_PYTHON_LOCATION =/app/wsgi.py
     - SPARK_MASTER_NAME=spark-master
     - SPARK_MASTER_PORT=7077
     - PYSPARK_PYTHON=python3
     - APP_SETTINGS=settings.ProductionConfig


  celery_beat:
    image: todhm/flask_spark_webapp
    working_dir: /app
    command: celery -A celery_worker:celery beat  --loglevel=INFO
    networks:
        - sparknetwork
    ports:
      - "9050:9050"
    depends_on:
      - webapp
      - spark-master
      - redis
      - celery_worker
    environment:
     - "SPARK_MASTER=spark://spark-master:7077"
     - SPARK_APPLICATION_PYTHON_LOCATION =/app/wsgi.py
     - SPARK_MASTER_NAME=spark-master
     - SPARK_MASTER_PORT=7077
     - PYSPARK_PYTHON=python3
     - APP_SETTINGS=settings.ProductionConfig

  mongo:
    image: mongo:3.4
    restart: always
    volumes:
      - db-data:/data/db
          volumes:
            - db-data:/data/db
            - ./mongo/shoppings:/shoppings
    networks:
      - sparknetwork

  redis:
    image: redis:alpine
    networks:
        - sparknetwork


  spark-master:
    image: bde2020/spark-master:2.3.0-hadoop2.7
    networks:
    - sparknetwork
    ports:
      - "8080:8080"
      - "7077:7077"
    deploy:
      placement:
        constraints: [node.hostname == default]

    environment:
      - INIT_DAEMON_STEP=setup_spark


  spark-worker-1:
    image: bde2020/spark-worker:2.3.0-hadoop2.7
    networks:
    - sparknetwork

    deploy:
      placement:
        constraints: [node.hostname == default]
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"


  spark-worker-2:
    image: bde2020/spark-worker:2.3.0-hadoop2.7
    networks:
    - sparknetwork
    depends_on:
      - spark-master
    deploy:
        replicas: 10
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"


volumes:
  db-data:

networks:
    sparknetwork:
