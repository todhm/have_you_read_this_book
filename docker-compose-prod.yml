version: '3.6'
services:

  webapp:
    image: todhm/flask_spark_webapp
    working_dir: /app
    command: gunicorn -b 0.0.0.0:8000 --reload -w 4  wsgi:app
    networks:
        - sparknetwork
    deploy:
      placement:
        constraints: [node.hostname == default]
    ports:
      - "8000:8000"
    depends_on:
      - spark-master
      - redis
      - mongo
    environment:
     - SPARK_APPLICATION_PYTHON_LOCATION =/app/wsgi.py
     - SPARK_MASTER_NAME=spark-master
     - SPARK_MASTER_PORT=7077
     - PYSPARK_PYTHON=python3
     - APP_SETTINGS=settings.ProductionConfig

  celery_worker:
    image: todhm/flask_spark_webapp
    working_dir: /app
    command: celery -A celery_worker:celery worker  --loglevel=INFO
    networks:
        - sparknetwork
    ports:
      - "9000:9000"

    deploy:
      placement:
        constraints: [node.hostname == default]

    depends_on:
      - webapp
      - spark-master
      - redis
    environment:
     - "SPARK_MASTER=spark://spark-master:7077"
     - SPARK_APPLICATION_PYTHON_LOCATION =/app/wsgi.py
     - SPARK_MASTER_NAME=spark-master
     - SPARK_MASTER_PORT=7077
     - PYSPARK_PYTHON=python3
     - APP_SETTINGS=settings.ProductionConfig


  celery_beat:
    image: todhm/flask_spark_webapp
    working_dir: /app
    command: celery -A celery_worker:celery beat  --loglevel=INFO
    networks:
        - sparknetwork
    ports:
      - "9050:9050"
    depends_on:
      - webapp
      - spark-master
      - redis
      - celery_worker
    environment:
     - "SPARK_MASTER=spark://spark-master:7077"
     - SPARK_APPLICATION_PYTHON_LOCATION =/app/wsgi.py
     - SPARK_MASTER_NAME=spark-master
     - SPARK_MASTER_PORT=7077
     - PYSPARK_PYTHON=python3
     - APP_SETTINGS=settings.ProductionConfig

  mongo:
    image: mongo:3.4
    command: mongos --port 27017 --configdb configserver/config01:27017,config02:27017,config03:27017
    ports:
      - 27017:27017
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - ./mongo/shoppings:/shoppings
      - ~/have_you_read_this_book/mongo/scripts/router.sh:/docker-entrypoint-initdb.d/router.sh
    networks:
      - sparknetwork
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == default
    depends_on:
      - config01
      - config02
      - config03
      - shard01a
      - shard01b
      - shard02a
      - shard02b
      - shard03a
      - shard03b
## Config Servers
  config01:
    image: mongo:3.4
    command: mongod --port 27017 --configsvr --replSet configserver --noprealloc --smallfiles --oplogSize 16
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - mongo-config-1:/data/db
      - ~/have_you_read_this_book/mongo/scripts/configserver.sh:/docker-entrypoint-initdb.d/configserver.sh
    networks:
        - sparknetwork


  config02:
    image: mongo:3.4
    command: mongod --port 27017 --configsvr --replSet configserver --noprealloc --smallfiles --oplogSize 16
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - mongo-config-2:/data/db
    networks:
        - sparknetwork

  config03:
    image: mongo:3.4
    command: mongod --port 27017 --configsvr --replSet configserver --noprealloc --smallfiles --oplogSize 16
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - mongo-config-3:/data/db
    networks:
        - sparknetwork

  ## Shards
  shard01a:
    image: mongo:3.4
    command: mongod --port 27018 --shardsvr --replSet shard01 --noprealloc --smallfiles --oplogSize 16
    ports:
      - 27018:27017
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - mongo-data-1:/data/db
      - ~/have_you_read_this_book/mongo/scripts/shard01.sh:/docker-entrypoint-initdb.d/shard01.sh
    networks:
        - sparknetwork


  shard01b:
    image: mongo:3.4
    command: mongod --port 27018 --shardsvr --replSet shard01 --noprealloc --smallfiles --oplogSize 16
    expose:
      - "27017"
    volumes:
      - mongo-data-1:/data/db
    networks:
        - sparknetwork

  shard02a:
    image: mongo:3.4
    command: mongod --port 27019 --shardsvr --replSet shard02 --noprealloc --smallfiles --oplogSize 16
    ports:
      - 27019:27017
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - mongo-data-2:/data/db
      - ~/have_you_read_this_book/mongo/scripts/shard02.sh:/docker-entrypoint-initdb.d/shard02.sh
    networks:
        - sparknetwork


  shard02b:
    image: mongo:3.4
    command: mongod --port 27019 --shardsvr --replSet shard02 --noprealloc --smallfiles --oplogSize 16
    expose:
      - "27017"
    volumes:
      - mongo-data-2:/data/db
    networks:
        - sparknetwork


  shard03a:
    image: mongo:3.4
    command: mongod --port 27020 --shardsvr --replSet shard03 --noprealloc --smallfiles --oplogSize 16
    ports:
      - 27020:27017
    expose:
      - "27017"
    volumes:
      - ~/have_you_read_this_book/mongo/scripts:/scripts
      - mongo-data-3:/data/db
      - ~/have_you_read_this_book/mongo/scripts/shard03.sh:/docker-entrypoint-initdb.d/shard03.sh
    networks:
        - sparknetwork


  shard03b:
    image: mongo:3.4
    command: mongod --port 27020 --shardsvr --replSet shard03 --noprealloc --smallfiles --oplogSize 16
    expose:
      - "27017"
    volumes:
      - mongo-data-3:/data/db
    networks:
        - sparknetwork


  redis:
    image: redis:alpine
    networks:
        - sparknetwork

  spark-master:
    image: bde2020/spark-master:2.3.0-hadoop2.7
    networks:
    - sparknetwork
    ports:
      - "8080:8080"
      - "7077:7077"
    deploy:
      placement:
        constraints: [node.hostname == default]

    environment:
      - INIT_DAEMON_STEP=setup_spark


  spark-worker-1:
    image: bde2020/spark-worker:2.3.0-hadoop2.7
    networks:
    - sparknetwork

    deploy:
      placement:
        constraints: [node.hostname == default]
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"


  spark-worker-2:
    image: bde2020/spark-worker:2.3.0-hadoop2.7
    networks:
    - sparknetwork
    depends_on:
      - spark-master
    deploy:
        replicas: 10
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"


volumes:
  mongo-data-1:
  mongo-data-2:
  mongo-data-3:
  mongo-config-1:
  mongo-config-2:
  mongo-config-3:

networks:
    sparknetwork:
